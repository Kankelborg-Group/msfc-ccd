{
 "cells": [
  {
   "cell_type": "raw",
   "id": "50f127d2",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Bias Estimation\n",
    "---------------\n",
    "\n",
    "On the Teledyne/e2v CCD230-42 sensors used by the MSFC camera,\n",
    "there are 50 `blank` columns at the start of each row,\n",
    "and 2 `overscan` columns at the end of each row.\n",
    "This report will investigate which combination of blank and overscan\n",
    "columns results in the best estimation of the bias using a single dark\n",
    "frame from the `EUV Snapshot Imaging Spectrograph` (ESIS) 2019 flight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a32676af4b941",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:26:24.782774Z",
     "start_time": "2025-07-23T19:26:19.599278Z"
    }
   },
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import named_arrays as na\n",
    "import msfc_ccd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad6039e0",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Start by defining the names of the horizontal and vertical axes of the sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a931cb92e4a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:57:45.875733Z",
     "start_time": "2025-07-23T13:57:45.872233Z"
    }
   },
   "outputs": [],
   "source": [
    "axis_x = \"x\"\n",
    "axis_y = \"y\"\n",
    "axis_xy = (axis_x, axis_y)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad4e09f6",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Load a single dark from the ESIS 2019 flight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e57d86aaae0b687",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:57:45.934733Z",
     "start_time": "2025-07-23T13:57:45.877234Z"
    }
   },
   "outputs": [],
   "source": [
    "dark = msfc_ccd.fits.open(\n",
    "    path=msfc_ccd.samples.path_dark_esis1,\n",
    "    axis_x=axis_x,\n",
    "    axis_y=axis_y,\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    figsize=(8, 4),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "im = na.plt.imshow(\n",
    "    dark.outputs,\n",
    "    axis_x=axis_x,\n",
    "    axis_y=axis_y,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(\"detector $x$ (pix)\")\n",
    "ax.set_ylabel(\"detector $y$ (pix)\")\n",
    "plt.colorbar(im.ndarray.item(), ax=ax, label=\"signal (DN)\");"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb3fcd5a",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Define the names of the logical axes of the 4 taps on the sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0984a54312eb8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:57:45.939732Z",
     "start_time": "2025-07-23T13:57:45.936235Z"
    }
   },
   "outputs": [],
   "source": [
    "axis_tap_x = \"tap_x\"\n",
    "axis_tap_y = \"tap_y\"\n",
    "axis_tap_xy = (axis_tap_x, axis_tap_y)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd333feb",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Split the dark image up into separate images for each tap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8bc37e7f5faa91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:57:46.535734Z",
     "start_time": "2025-07-23T13:57:45.940732Z"
    }
   },
   "outputs": [],
   "source": [
    "taps = dark.taps(axis_tap_x, axis_tap_y)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0ef30d9",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Plot the average dark signal for each column in each tap, along with the blank and overscan regions for each tap.\n",
    "Notice that the signal in the blank columns is often a poor representation of the average signal along all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa35d7488063e50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:57:47.080235Z",
     "start_time": "2025-07-23T13:57:46.538233Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = na.plt.subplots(\n",
    "    axis_rows=axis_tap_y,\n",
    "    axis_cols=axis_tap_x,\n",
    "    nrows=taps.shape[axis_tap_y],\n",
    "    ncols=taps.shape[axis_tap_x],\n",
    "    sharex=True,\n",
    "    constrained_layout=True,\n",
    ")\n",
    "na.plt.plot(\n",
    "    taps.outputs.mean_trimmed(.01, axis_y),\n",
    "    axis=axis_x,\n",
    "    ax=ax,\n",
    ")\n",
    "na.plt.set_ylim(\n",
    "    bottom=taps.outputs.percentile(5, axis=axis_xy),\n",
    "    top=taps.outputs.percentile(95, axis=axis_xy),\n",
    "    ax=ax,\n",
    ")\n",
    "na.plt.axvspan(\n",
    "    xmin=0,\n",
    "    xmax=taps.camera.sensor.num_blank,\n",
    "    color=\"green\",\n",
    "    alpha=0.2,\n",
    "    ax=ax,\n",
    "    label=\"blank columns\",\n",
    ")\n",
    "na.plt.axvspan(\n",
    "    xmin=taps.num_x - taps.camera.sensor.num_overscan,\n",
    "    xmax=taps.num_x,\n",
    "    color=\"red\",\n",
    "    alpha=0.2,\n",
    "    ax=ax,\n",
    "    label=\"overscan columns\",\n",
    ")\n",
    "na.plt.set_ylabel(\"row-averaged signal (DN)\", ax[{axis_tap_x: 0}])\n",
    "na.plt.set_xlabel(\"columns\", ax=ax[{axis_tap_y: 0}])\n",
    "na.plt.text(\n",
    "    x=0.9,\n",
    "    y=0.95,\n",
    "    s=taps.label,\n",
    "    ax=ax,\n",
    "    transform=na.plt.transAxes(ax),\n",
    "    ha=\"right\",\n",
    "    va=\"top\",\n",
    ")\n",
    "ax.ndarray.flat[0].legend();"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70bbf67f",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "With this in mind, we'll use :meth:`msfc_ccd.TapData.bias` to estimate the bias from `only` the blank columns `or` the overscan columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec476114e5c971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:57:47.105732Z",
     "start_time": "2025-07-23T13:57:47.087236Z"
    }
   },
   "outputs": [],
   "source": [
    "bias_blank = taps.bias(num_blank=None, num_overscan=0)\n",
    "bias_overscan = taps.bias(num_blank=0, num_overscan=None)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9af51b6",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Then, we'll subtract the bias estimated using these two regions from each tap image,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3ad6cc163af910",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:57:47.171233Z",
     "start_time": "2025-07-23T13:57:47.106732Z"
    }
   },
   "outputs": [],
   "source": [
    "unbiased_blank = taps - bias_blank\n",
    "unbiased_overscan = taps - bias_overscan"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5765363",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "and smooth the result slightly to make it easier to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180580bdf42424d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:57:55.309231Z",
     "start_time": "2025-07-23T13:57:47.172733Z"
    }
   },
   "outputs": [],
   "source": [
    "kwargs_filter = dict(\n",
    "    size={axis_x: 11, axis_y: 11},\n",
    "    proportion=0.05,\n",
    ")\n",
    "unbiased_blank = na.ndfilters.trimmed_mean_filter(unbiased_blank, **kwargs_filter)\n",
    "unbiased_overscan = na.ndfilters.trimmed_mean_filter(unbiased_overscan, **kwargs_filter)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e45b6caf",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Finally, we'll take the tap images and reconstruct them into a bias-subtracted dark frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168a02472ab0841a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:57:55.363231Z",
     "start_time": "2025-07-23T13:57:55.310731Z"
    }
   },
   "outputs": [],
   "source": [
    "dark_blank = dark.from_taps(unbiased_blank)\n",
    "dark_overscan = dark.from_taps(unbiased_overscan)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b3005a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:58:00.863232Z",
     "start_time": "2025-07-23T13:57:55.364518Z"
    },
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Now, if we make a histogram of the smoothed, bias-subtracted tap image pixel values,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2676af57c28a2324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:59:19.411869Z",
     "start_time": "2025-07-23T13:59:18.956367Z"
    }
   },
   "outputs": [],
   "source": [
    "kwargs_hist = dict(\n",
    "    axis=axis_xy,\n",
    "    bins=na.arange(-2, 2, \"xy\", .1),\n",
    "    density=True,\n",
    ")\n",
    "hist_blank = na.histogram(unbiased_blank.outputs, **kwargs_hist)\n",
    "hist_overscan = na.histogram(unbiased_overscan.outputs, **kwargs_hist)\n",
    "\n",
    "fig, ax = na.plt.subplots(\n",
    "    axis_rows=axis_tap_y,\n",
    "    axis_cols=axis_tap_x,\n",
    "    nrows=taps.shape[axis_tap_y],\n",
    "    ncols=taps.shape[axis_tap_x],\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    constrained_layout=True,\n",
    ")\n",
    "na.plt.stairs(\n",
    "    hist_blank.inputs,\n",
    "    hist_blank.outputs,\n",
    "    ax=ax,\n",
    "    axis=\"xy\",\n",
    "    label=\"blank\",\n",
    ")\n",
    "na.plt.stairs(\n",
    "    hist_overscan.inputs,\n",
    "    hist_overscan.outputs,\n",
    "    ax=ax,\n",
    "    axis=\"xy\",\n",
    "    label=\"overscan\",\n",
    ")\n",
    "na.plt.text(\n",
    "    x=0.95,\n",
    "    y=0.95,\n",
    "    s=taps.label,\n",
    "    ax=ax,\n",
    "    transform=na.plt.transAxes(ax),\n",
    "    ha=\"right\",\n",
    "    va=\"top\",\n",
    ")\n",
    "na.plt.axvline(0, ax=ax, color=\"black\", linestyle=\"--\")\n",
    "na.plt.set_ylabel(\"probability density\", ax[{axis_tap_x: 0}])\n",
    "na.plt.set_xlabel(\"smoothed signal (DN)\", ax=ax[{axis_tap_y: 0}])\n",
    "ax[{axis_tap_x: 0, axis_tap_y: ~0}].ndarray.legend(loc=\"upper left\");"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a8a87cf",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "we can see that the bias based on the overscan pixels does a much better job of centering the distribution around zero.\n",
    "In fact, if we compare the trimmed mean of the blank-bias-subtracted taps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c9fdda6710b89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:58:01.328233Z",
     "start_time": "2025-07-23T13:58:01.303737Z"
    }
   },
   "outputs": [],
   "source": [
    "unbiased_blank.outputs.mean_trimmed(0.01, axis_xy)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69dc2cf4",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "to the trimmed mean of the overscan-bias-subtracted taps, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ab37aa5519209",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:58:01.353232Z",
     "start_time": "2025-07-23T13:58:01.329733Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unbiased_overscan.outputs.mean_trimmed(0.01, axis_xy)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2aa2b05b",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "we can see that the average is much closer to zero using the bias computed from the overscan pixels."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae933040",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "One final visualization we can do is blink the blank-bias-subtracted dark image against the overscan-bias-subtracted dark image to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3bc0374dad4687",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:40:53.279977Z",
     "start_time": "2025-07-23T14:40:48.793478Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "colorizer = plt.Colorizer(\n",
    "    norm=plt.Normalize(\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "    ),\n",
    ")\n",
    "ani = na.plt.pcolormovie(\n",
    "    na.ScalarArray(\n",
    "        ndarray=np.array([\"blank\", \"overscan\"]),\n",
    "        axes=\"blink\",\n",
    "    ),\n",
    "    dark.inputs.pixel.x,\n",
    "    dark.inputs.pixel.y,\n",
    "    C=na.stack(\n",
    "        arrays=[dark_blank.outputs, dark_overscan.outputs],\n",
    "        axis=\"blink\",\n",
    "    ),\n",
    "    axis_time=\"blink\",\n",
    "    ax=ax,\n",
    "    kwargs_pcolormesh=dict(\n",
    "        colorizer=colorizer,\n",
    "    ),\n",
    "    kwargs_animation=dict(\n",
    "        interval=1000,\n",
    "    )\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"detector $x$ (pix)\")\n",
    "ax.set_ylabel(\"detector $y$ (pix)\")\n",
    "plt.colorbar(\n",
    "    mappable=plt.cm.ScalarMappable(colorizer=colorizer), \n",
    "    ax=ax,\n",
    "    label=\"signal (DN)\"\n",
    ")\n",
    "plt.close(fig)\n",
    "IPython.display.HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1bc3cc6c",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "This shows that the overscan-bias-subtracted dark image is much better at removing the seams in between each tap."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8eff7ec8",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "In conclusion, we recommend to only use the overscan columns to compute the bias, unless other MSFC cameras than the single one studied here have much different behavior.\n",
    "For that reason, we have set the arguments of :meth:`msfc_ccd.TapData.bias` to use only the overscan columns by default."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
